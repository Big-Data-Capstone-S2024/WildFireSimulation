{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('engineered_wildfire_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 450342 entries, 0 to 450341\n",
      "Data columns (total 32 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   temp        450342 non-null  float64\n",
      " 1   rh          450342 non-null  float64\n",
      " 2   ws          450342 non-null  float64\n",
      " 3   wd          450342 non-null  int64  \n",
      " 4   pcp         450342 non-null  float64\n",
      " 5   ffmc        450342 non-null  float64\n",
      " 6   dmc         450342 non-null  float64\n",
      " 7   dc          450342 non-null  float64\n",
      " 8   isi         450342 non-null  float64\n",
      " 9   bui         450342 non-null  float64\n",
      " 10  fwi         450342 non-null  float64\n",
      " 11  ros         450339 non-null  float64\n",
      " 12  sfc         450339 non-null  float64\n",
      " 13  tfc         450339 non-null  float64\n",
      " 14  bfc         239132 non-null  float64\n",
      " 15  hfi         450339 non-null  float64\n",
      " 16  cfb         450339 non-null  float64\n",
      " 17  pcuring     425990 non-null  float64\n",
      " 18  greenup     425990 non-null  float64\n",
      " 19  elev        450342 non-null  int64  \n",
      " 20  sfl         450342 non-null  float64\n",
      " 21  cfl         450342 non-null  float64\n",
      " 22  tfc0        450339 non-null  float64\n",
      " 23  sfc0        450339 non-null  float64\n",
      " 24  year        450342 non-null  int64  \n",
      " 25  month       450342 non-null  int64  \n",
      " 26  day         450342 non-null  int64  \n",
      " 27  lat_sin     450342 non-null  float64\n",
      " 28  lat_cos     450342 non-null  float64\n",
      " 29  lon_sin     450342 non-null  float64\n",
      " 30  lon_cos     450342 non-null  float64\n",
      " 31  year_month  450342 non-null  object \n",
      "dtypes: float64(26), int64(5), object(1)\n",
      "memory usage: 109.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>rh</th>\n",
       "      <th>ws</th>\n",
       "      <th>wd</th>\n",
       "      <th>pcp</th>\n",
       "      <th>ffmc</th>\n",
       "      <th>dmc</th>\n",
       "      <th>dc</th>\n",
       "      <th>isi</th>\n",
       "      <th>bui</th>\n",
       "      <th>...</th>\n",
       "      <th>tfc0</th>\n",
       "      <th>sfc0</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>lat_sin</th>\n",
       "      <th>lat_cos</th>\n",
       "      <th>lon_sin</th>\n",
       "      <th>lon_cos</th>\n",
       "      <th>year_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.006741</td>\n",
       "      <td>2.094934</td>\n",
       "      <td>-0.649149</td>\n",
       "      <td>320</td>\n",
       "      <td>0.430</td>\n",
       "      <td>82.976</td>\n",
       "      <td>30.078</td>\n",
       "      <td>161.161</td>\n",
       "      <td>2.680</td>\n",
       "      <td>41.018</td>\n",
       "      <td>...</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.35</td>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.883899</td>\n",
       "      <td>0.467678</td>\n",
       "      <td>-0.311904</td>\n",
       "      <td>-0.950114</td>\n",
       "      <td>2020-6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.423696</td>\n",
       "      <td>0.992790</td>\n",
       "      <td>-0.700308</td>\n",
       "      <td>145</td>\n",
       "      <td>1.237</td>\n",
       "      <td>68.466</td>\n",
       "      <td>0.000</td>\n",
       "      <td>294.020</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>0.879890</td>\n",
       "      <td>0.475177</td>\n",
       "      <td>-0.268096</td>\n",
       "      <td>-0.963392</td>\n",
       "      <td>2020-6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.226618</td>\n",
       "      <td>1.122454</td>\n",
       "      <td>-0.867970</td>\n",
       "      <td>30</td>\n",
       "      <td>0.591</td>\n",
       "      <td>88.685</td>\n",
       "      <td>55.743</td>\n",
       "      <td>202.448</td>\n",
       "      <td>5.536</td>\n",
       "      <td>66.032</td>\n",
       "      <td>...</td>\n",
       "      <td>1.36</td>\n",
       "      <td>1.36</td>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>0.736971</td>\n",
       "      <td>0.675925</td>\n",
       "      <td>-0.939322</td>\n",
       "      <td>0.343037</td>\n",
       "      <td>2020-6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.366794</td>\n",
       "      <td>-1.665321</td>\n",
       "      <td>-0.843150</td>\n",
       "      <td>271</td>\n",
       "      <td>0.000</td>\n",
       "      <td>98.652</td>\n",
       "      <td>290.568</td>\n",
       "      <td>841.230</td>\n",
       "      <td>22.181</td>\n",
       "      <td>311.848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.35</td>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>0.535709</td>\n",
       "      <td>0.844403</td>\n",
       "      <td>-0.934801</td>\n",
       "      <td>-0.355172</td>\n",
       "      <td>2020-6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.170139</td>\n",
       "      <td>0.020311</td>\n",
       "      <td>-0.000958</td>\n",
       "      <td>50</td>\n",
       "      <td>0.001</td>\n",
       "      <td>91.660</td>\n",
       "      <td>18.664</td>\n",
       "      <td>102.620</td>\n",
       "      <td>10.972</td>\n",
       "      <td>25.660</td>\n",
       "      <td>...</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.35</td>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>0.551529</td>\n",
       "      <td>0.834155</td>\n",
       "      <td>-0.999729</td>\n",
       "      <td>-0.023267</td>\n",
       "      <td>2020-6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       temp        rh        ws   wd    pcp    ffmc      dmc       dc     isi  \\\n",
       "0 -1.006741  2.094934 -0.649149  320  0.430  82.976   30.078  161.161   2.680   \n",
       "1  0.423696  0.992790 -0.700308  145  1.237  68.466    0.000  294.020   0.977   \n",
       "2  0.226618  1.122454 -0.867970   30  0.591  88.685   55.743  202.448   5.536   \n",
       "3  1.366794 -1.665321 -0.843150  271  0.000  98.652  290.568  841.230  22.181   \n",
       "4  1.170139  0.020311 -0.000958   50  0.001  91.660   18.664  102.620  10.972   \n",
       "\n",
       "       bui  ...  tfc0  sfc0  year  month  day   lat_sin   lat_cos   lon_sin  \\\n",
       "0   41.018  ...  0.35  0.35  2020      6    2  0.883899  0.467678 -0.311904   \n",
       "1    0.000  ...  0.10  0.10  2020      6   11  0.879890  0.475177 -0.268096   \n",
       "2   66.032  ...  1.36  1.36  2020      6   20  0.736971  0.675925 -0.939322   \n",
       "3  311.848  ...  0.35  0.35  2020      6   22  0.535709  0.844403 -0.934801   \n",
       "4   25.660  ...  0.35  0.35  2020      6   13  0.551529  0.834155 -0.999729   \n",
       "\n",
       "    lon_cos  year_month  \n",
       "0 -0.950114      2020-6  \n",
       "1 -0.963392      2020-6  \n",
       "2  0.343037      2020-6  \n",
       "3 -0.355172      2020-6  \n",
       "4 -0.023267      2020-6  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "temp               0\n",
       "rh                 0\n",
       "ws                 0\n",
       "wd                 0\n",
       "pcp                0\n",
       "ffmc               0\n",
       "dmc                0\n",
       "dc                 0\n",
       "isi                0\n",
       "bui                0\n",
       "fwi                0\n",
       "ros                3\n",
       "sfc                3\n",
       "tfc                3\n",
       "bfc           211210\n",
       "hfi                3\n",
       "cfb                3\n",
       "pcuring        24352\n",
       "greenup        24352\n",
       "elev               0\n",
       "sfl                0\n",
       "cfl                0\n",
       "tfc0               3\n",
       "sfc0               3\n",
       "year               0\n",
       "month              0\n",
       "day                0\n",
       "lat_sin            0\n",
       "lat_cos            0\n",
       "lon_sin            0\n",
       "lon_cos            0\n",
       "year_month         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(['year', 'month', 'day'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_features = [\n",
    "    'temp',    # Temperature\n",
    "    'rh',      # Relative Humidity\n",
    "    'ws',      # Wind Speed\n",
    "    'wd',      # Wind Direction\n",
    "    'ffmc',    # Fine Fuel Moisture Code\n",
    "    'dmc',     # Duff Moisture Code\n",
    "    'dc',      # Drought Code\n",
    "    'isi',     # Initial Spread Index\n",
    "    'bui',     # Buildup Index\n",
    "    'fwi',     # Fire Weather Index\n",
    "    'ros',     # Rate of Spread\n",
    "    'sfc',     # Surface Fuel Consumption\n",
    "    'tfc',     # Total Fuel Consumption\n",
    "    'hfi',     # Head Fire Intensity\n",
    "    'pcuring', # Percent Curing (if available)\n",
    "    'elev',    # Elevation\n",
    "    'sfl',     # Surface Fuel Load (if this represents available surface fuels)\n",
    "    'cfl'      # Crown Fuel Load\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-based features\n",
    "time_features = ['year', 'month', 'day']\n",
    "# Note: 'year_month' is omitted as it's likely redundant with 'year' and 'month'\n",
    "\n",
    "# Derived features\n",
    "derived_features = [\n",
    "    'temp_lag_1',     # Temperature from previous time step\n",
    "    'ws_lag_1',       # Wind speed from previous time step\n",
    "    'rh_lag_1',       # Relative humidity from previous time step\n",
    "    'ffmc_lag_1',     # FFMC from previous time step\n",
    "    'isi_lag_1',      # ISI from previous time step\n",
    "    'fwi_lag_1',      # FWI from previous time step\n",
    "    'drought_index',  # Composite drought index (e.g., (dc + dmc) / 2)\n",
    "    'day_of_year',    # Calculated from year, month, day\n",
    "    'season'          # Derived from month (e.g., Spring, Summer, Fall, Winter)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all features\n",
    "all_features = primary_features + time_features + derived_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoformerConfig, AutoformerModel\n",
    "\n",
    "config = AutoformerConfig(\n",
    "    prediction_length=24,  # Adjust based on your forecasting needs\n",
    "    context_length=72,  # Typically 3x prediction_length\n",
    "    input_size=len(all_features),\n",
    "    lags_sequence=[1, 2, 3, 4, 5, 6, 7],\n",
    "    num_time_features=len(time_features) + 2,  # year, month, day, day_of_year, season\n",
    "    num_static_real_features=1,  # Only elevation is static\n",
    "    num_dynamic_real_features=len(all_features) - len(time_features) - 3,  # Subtracting time features and elevation\n",
    "    d_model=64,\n",
    "    encoder_layers=2,\n",
    "    decoder_layers=2,\n",
    "    encoder_attention_heads=2,\n",
    "    decoder_attention_heads=2,\n",
    "    encoder_ffn_dim=128,\n",
    "    decoder_ffn_dim=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derive_features(df):\n",
    "    # Ensure datetime index\n",
    "    df['date'] = pd.to_datetime(df['year'].astype(str) + '-' + df['month'].astype(str) + '-' + df['day'].astype(str))\n",
    "    df.set_index('date', inplace=True)\n",
    "    \n",
    "    # Create day of year\n",
    "    df['day_of_year'] = df.index.dayofyear\n",
    "    \n",
    "    # Create season\n",
    "    df['season'] = pd.cut(df['month'], bins=[0, 3, 6, 9, 12], labels=['Winter', 'Spring', 'Summer', 'Fall'])\n",
    "    \n",
    "    # Create lag features\n",
    "    for feature in ['temp', 'ws', 'rh', 'ffmc', 'isi', 'fwi']:\n",
    "        df[f'{feature}_lag_1'] = df[feature].shift(1)\n",
    "    \n",
    "    # Create drought index\n",
    "    df['drought_index'] = (df['dc'] + df['dmc']) / 2\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply the function to your dataframe\n",
    "df = derive_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([df[all_features], df['cfb']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "def prepare_data(df, target_column='cfb', test_size=0.2, sequence_length=30):\n",
    "    # Ensure the dataframe is sorted by date\n",
    "    df = df.sort_index()\n",
    "\n",
    "    # Separate the target column from the features\n",
    "    features = df.drop(columns=[target_column])\n",
    "    target = df[target_column]\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    train_features, test_features, train_target, test_target = train_test_split(\n",
    "        features, target, test_size=test_size, shuffle=False\n",
    "    )\n",
    "\n",
    "    # Identify categorical and numerical features\n",
    "    categorical_features = ['season']\n",
    "    numeric_features = train_features.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "\n",
    "    # Create the preprocessing pipelines for both numeric and categorical data\n",
    "    numeric_transformer = StandardScaler()\n",
    "    categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "    # Combine the transformers into a preprocessor\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Apply the transformations to train and test data\n",
    "    train_features_scaled = preprocessor.fit_transform(train_features)\n",
    "    test_features_scaled = preprocessor.transform(test_features)\n",
    "\n",
    "    # Convert the transformed data back to DataFrame\n",
    "    train_features_scaled_df = pd.DataFrame(train_features_scaled, index=train_features.index)\n",
    "    test_features_scaled_df = pd.DataFrame(test_features_scaled, index=test_features.index)\n",
    "\n",
    "    # Add the target column back to the scaled data\n",
    "    train_scaled = train_features_scaled_df.copy()\n",
    "    train_scaled[target_column] = train_target\n",
    "    test_scaled = test_features_scaled_df.copy()\n",
    "    test_scaled[target_column] = test_target\n",
    "\n",
    "    # Function to create sequences\n",
    "    def create_sequences(data, target_column, sequence_length):\n",
    "        X, y = [], []\n",
    "        for i in range(len(data) - sequence_length):\n",
    "            X.append(data.iloc[i:i+sequence_length].drop(columns=[target_column]).values)\n",
    "            y.append(data.iloc[i+sequence_length][target_column])\n",
    "        return np.array(X), np.array(y)\n",
    "    \n",
    "    # Create sequences\n",
    "    X_train, y_train = create_sequences(train_scaled, target_column, sequence_length)\n",
    "    X_test, y_test = create_sequences(test_scaled, target_column, sequence_length)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test, preprocessor\n",
    "\n",
    "# Prepare the data\n",
    "X_train, y_train, X_test, y_test, preprocessor = prepare_data(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "\n",
    "# Convert data to PyTorch tensors and create DataLoaders\n",
    "train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32))\n",
    "test_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32))\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train the model\n",
    "# from torch.optim import Adam\n",
    "# from torch.nn import MSELoss\n",
    "# import torch\n",
    "\n",
    "# optimizer = Adam(model.parameters())\n",
    "# loss_function = MSELoss()\n",
    "\n",
    "# num_epochs = 100\n",
    "# batch_size = 32\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     model.train()\n",
    "#     total_loss = 0\n",
    "#     for i in range(0, len(X_train), batch_size):\n",
    "#         batch_X = torch.FloatTensor(X_train[i:i+batch_size])\n",
    "#         batch_y = torch.FloatTensor(y_train[i:i+batch_size])\n",
    "        \n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(batch_X)\n",
    "#         loss = loss_function(outputs, batch_y.unsqueeze(1))\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         total_loss += loss.item()\n",
    "    \n",
    "#     print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(X_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "class AutoformerLightningModule(pl.LightningModule):\n",
    "    def __init__(self, model, learning_rate=1e-4):\n",
    "        super(AutoformerLightningModule, self).__init__()\n",
    "        self.model = model\n",
    "        self.learning_rate = learning_rate\n",
    "        self.loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x).logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "        self.log('val_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing a default Autoformer configuration\n",
    "configuration = AutoformerConfig()\n",
    "\n",
    "# Randomly initializing a model (with random weights) from the configuration\n",
    "autoformer_model = AutoformerModel(configuration)\n",
    "\n",
    "# Creating the LightningModule with the Autoformer model\n",
    "model = AutoformerLightningModule(autoformer_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\annma\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\logger_connector\\logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "`model` must be a `LightningModule` or `torch._dynamo.OptimizedModule`, got `AutoformerModel`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[78], line 15\u001b[0m\n\u001b[0;32m      9\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(\n\u001b[0;32m     10\u001b[0m     max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[0;32m     11\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[early_stopping, checkpoint_callback]\n\u001b[0;32m     12\u001b[0m )\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\annma\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:537\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    503\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\n\u001b[0;32m    504\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    505\u001b[0m     model: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl.LightningModule\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m     ckpt_path: Optional[_PATH] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    510\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    511\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Runs the full optimization routine.\u001b[39;00m\n\u001b[0;32m    512\u001b[0m \n\u001b[0;32m    513\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    535\u001b[0m \n\u001b[0;32m    536\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 537\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_unwrap_optimized\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m_lightning_module \u001b[38;5;241m=\u001b[39m model\n\u001b[0;32m    539\u001b[0m     _verify_strategy_supports_compile(model, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy)\n",
      "File \u001b[1;32mc:\\Users\\annma\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\utilities\\compile.py:116\u001b[0m, in \u001b[0;36m_maybe_unwrap_optimized\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[0;32m    115\u001b[0m _check_mixed_imports(model)\n\u001b[1;32m--> 116\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`model` must be a `LightningModule` or `torch._dynamo.OptimizedModule`, got `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(model)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    118\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: `model` must be a `LightningModule` or `torch._dynamo.OptimizedModule`, got `AutoformerModel`"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# Define callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=True, mode='min')\n",
    "checkpoint_callback_best = ModelCheckpoint(monitor='val_loss', save_top_k=1, mode='min', \\\n",
    "                                           dirpath='/kaggle/working/model_checkpoints/', \\\n",
    "                                           filename='best_model')\n",
    "checkpoint_callback_interval = ModelCheckpoint(every_n_epochs=5, save_top_k=-1, \\\n",
    "                                               dirpath='/kaggle/working/model_checkpoints/', \\\n",
    "                                               filename='model_epoch{epoch:02d}')\n",
    "\n",
    "# Initialize the PyTorch Lightning trainer\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=50,\n",
    "    callbacks=[early_stopping, checkpoint_callback_best, checkpoint_callback_interval]\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
