{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pymongo requests beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pymongo pyshp\n",
    "# !pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import zipfile\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "from pymongo import MongoClient, errors\n",
    "import time\n",
    "from urllib.parse import urljoin\n",
    "from bs4 import BeautifulSoup\n",
    "import shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo.errors import ConnectionFailure\n",
    "import logging\n",
    "import time\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_zip_files(base_url):\n",
    "    \"\"\"Lists all ZIP files in the directory at the given base URL.\"\"\"\n",
    "    response = requests.get(base_url)\n",
    "    response.raise_for_status()\n",
    "    html_content = response.text\n",
    "\n",
    "    # Assuming the server lists files as links in the HTML\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    zip_files = [urljoin(base_url, link.get('href')) for link in soup.find_all('a') if link.get('href').endswith('.zip')]\n",
    "    return zip_files\n",
    "\n",
    "def download_zip(url, save_path):\n",
    "    \"\"\"Downloads a ZIP file from a URL to the specified local path.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    with open(save_path, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "\n",
    "def extract_zip(zip_path, extract_to):\n",
    "    \"\"\"Extracts the ZIP file to the specified directory.\"\"\"\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "        \n",
    "def shape_record_to_geojson(shape_record):\n",
    "    \"\"\"Convert a shapefile record to a GeoJSON feature.\"\"\"\n",
    "    geom = shape_record.shape.__geo_interface__\n",
    "    properties = shape_record.record.as_dict()\n",
    "    feature = {\n",
    "        \"type\": \"Feature\",\n",
    "        \"geometry\": geom,\n",
    "        \"properties\": properties\n",
    "    }\n",
    "    return feature\n",
    "\n",
    "def read_shapefiles(directory):\n",
    "    \"\"\"Reads all shapefiles in the specified directory and returns their contents as GeoJSON.\"\"\"\n",
    "    data = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.shp'):\n",
    "            shp_path = os.path.join(directory, filename)\n",
    "            print(f\"Reading shapefile: {shp_path}\")  # Debug statement\n",
    "            reader = shapefile.Reader(shp_path)\n",
    "            features = [shape_record_to_geojson(sr) for sr in reader.shapeRecords()]\n",
    "            data.extend(features)\n",
    "    return data\n",
    "\n",
    "def connect_to_mongo(uri, retries=5, delay=5):\n",
    "    for attempt in range(1, retries + 1):\n",
    "        try:\n",
    "            logger.info(f\"Attempt {attempt}: Connecting to MongoDB...\")\n",
    "            client = MongoClient(uri, serverSelectionTimeoutMS=5000)\n",
    "            client.server_info()  # Force connection on a request as the connect=True parameter of MongoClient seems to be useless here\n",
    "            logger.info(\"Connected to MongoDB successfully.\")\n",
    "            return client\n",
    "        except ConnectionFailure as e:\n",
    "            logger.error(f\"Attempt {attempt} failed: {e}\")\n",
    "            if attempt < retries:\n",
    "                logger.info(f\"Retrying in {delay} seconds...\")\n",
    "                time.sleep(delay)\n",
    "            else:\n",
    "                logger.error(\"All retry attempts failed.\")\n",
    "                raise\n",
    "\n",
    "def insert_data_to_mongodb(data, db_name, collection_name, mongo_uri):\n",
    "    client = MongoClient(mongo_uri)\n",
    "    db = client[db_name]\n",
    "    collection = db[collection_name]\n",
    "    print('inserting....')\n",
    "    collection.insert_many(data)\n",
    "\n",
    "def filter_zip_files_by_year(zip_files, start_year, end_year):\n",
    "    \"\"\"Filters ZIP files based on the year range in their names.\"\"\"\n",
    "    filtered_files = []\n",
    "    for file_url in zip_files:\n",
    "        # Extract year from file name, assuming format 'YYYY_...'\n",
    "        file_name = os.path.basename(file_url)\n",
    "        try:\n",
    "            year = int(file_name.split('_')[0])\n",
    "            if start_year <= year <= end_year:\n",
    "                filtered_files.append(file_url)\n",
    "        except ValueError:\n",
    "            pass\n",
    "    return filtered_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the variables\n",
    "base_url = os.getenv('BASE_URL')\n",
    "extract_to = os.getenv('EXTRACT_TO')\n",
    "db_name = os.getenv('DB_NAME')\n",
    "collection_name = os.getenv('COLLECTION_NAME')\n",
    "mongo_uri = os.getenv('MONGO_URI')\n",
    "start_year = os.getenv('START_YEAR')\n",
    "end_year = os.getenv('END_YEAR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Attempt 1: Connecting to MongoDB...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pymongo.serverSelection:{\"message\": \"Waiting for suitable server to become available\", \"selector\": \"Primary()\", \"operation\": \"buildinfo\", \"topologyDescription\": \"<TopologyDescription id: 665e6f63dc81e1917aee5181, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('ac-wzg1yil-shard-00-00.vmiph7u.mongodb.net', 27017) server_type: Unknown, rtt: None>, <ServerDescription ('ac-wzg1yil-shard-00-01.vmiph7u.mongodb.net', 27017) server_type: Unknown, rtt: None>, <ServerDescription ('ac-wzg1yil-shard-00-02.vmiph7u.mongodb.net', 27017) server_type: Unknown, rtt: None>]>\", \"clientId\": {\"$oid\": \"665e6f63dc81e1917aee5181\"}, \"remainingTimeMS\": 4}\n",
      "INFO:__main__:Connected to MongoDB successfully.\n"
     ]
    }
   ],
   "source": [
    "client = connect_to_mongo(mongo_uri)\n",
    "\n",
    "# Access the database and collection\n",
    "db = client[db_name]\n",
    "collection = db[collection_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading shapefile: extracted_data/2013_hotspots.shp\n",
      "First record:\n",
      "{\n",
      "  \"type\": \"Feature\",\n",
      "  \"geometry\": {\n",
      "    \"type\": \"Point\",\n",
      "    \"coordinates\": [\n",
      "      -21936.408456150224,\n",
      "      1039492.9271111382\n",
      "    ]\n",
      "  },\n",
      "  \"properties\": {\n",
      "    \"LAT\": 58.479,\n",
      "    \"LON\": -95.386,\n",
      "    \"REP_DATE\": \"2013-06-30 19:35:00\",\n",
      "    \"UID\": 6156137,\n",
      "    \"SOURCE\": \"NASA\",\n",
      "    \"SENSOR\": \"MODIS\",\n",
      "    \"SATELLITE\": \"Aqua\",\n",
      "    \"AGENCY\": \"MB\",\n",
      "    \"TEMP\": 24.8,\n",
      "    \"RH\": 42,\n",
      "    \"WS\": 14.8,\n",
      "    \"WD\": 240,\n",
      "    \"PCP\": 0.0,\n",
      "    \"FFMC\": null,\n",
      "    \"DMC\": null,\n",
      "    \"DC\": null,\n",
      "    \"ISI\": null,\n",
      "    \"BUI\": null,\n",
      "    \"FWI\": 0.0,\n",
      "    \"FUEL\": \"C2\",\n",
      "    \"ROS\": 0.0,\n",
      "    \"SFC\": 0.0,\n",
      "    \"TFC\": 0.0,\n",
      "    \"BFC\": 0.0,\n",
      "    \"HFI\": 0,\n",
      "    \"CFB\": null,\n",
      "    \"AGE\": 12137,\n",
      "    \"ESTAREA\": 73.33,\n",
      "    \"POLYID\": 5822612,\n",
      "    \"PCURING\": 50,\n",
      "    \"CFACTOR\": 0.100577,\n",
      "    \"GREENUP\": 1,\n",
      "    \"ELEV\": null\n",
      "  }\n",
      "}\n",
      "{'type': 'Feature', 'geometry': {'type': 'Point', 'coordinates': (-21936.408456150224, 1039492.9271111382)}, 'properties': {'LAT': 58.479, 'LON': -95.386, 'REP_DATE': '2013-06-30 19:35:00', 'UID': 6156137, 'SOURCE': 'NASA', 'SENSOR': 'MODIS', 'SATELLITE': 'Aqua', 'AGENCY': 'MB', 'TEMP': 24.8, 'RH': 42, 'WS': 14.8, 'WD': 240, 'PCP': 0.0, 'FFMC': None, 'DMC': None, 'DC': None, 'ISI': None, 'BUI': None, 'FWI': 0.0, 'FUEL': 'C2', 'ROS': 0.0, 'SFC': 0.0, 'TFC': 0.0, 'BFC': 0.0, 'HFI': 0, 'CFB': None, 'AGE': 12137, 'ESTAREA': 73.33, 'POLYID': 5822612, 'PCURING': 50, 'CFACTOR': 0.100577, 'GREENUP': 1, 'ELEV': None}}\n"
     ]
    }
   ],
   "source": [
    "from bson import BSON\n",
    "# Steps\n",
    "zip_files = list_zip_files(base_url)\n",
    "filtered_zip_files = filter_zip_files_by_year(zip_files, int(start_year), int(end_year))\n",
    "\n",
    "for zip_url in filtered_zip_files:\n",
    "    zip_path = os.path.join('downloads', os.path.basename(zip_url))\n",
    "    os.makedirs('downloads', exist_ok=True)\n",
    "    download_zip(zip_url, zip_path)\n",
    "    extract_zip(zip_path, extract_to) \n",
    "    data = read_shapefiles(extract_to)\n",
    "     # Print first record as JSON\n",
    "    if len(data) > 0:\n",
    "        print(\"First record:\")\n",
    "        print(json.dumps(data[0], indent=2)) \n",
    "        print(data[0])\n",
    "    bson_data = BSON.encode(data)\n",
    "    insert_data_to_mongodb(bson_data, db_name, collection_name, mongo_uri)\n",
    "    os.remove(zip_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
