{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/engineered_wildfire_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 450342 entries, 0 to 450341\n",
      "Data columns (total 32 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   temp        450342 non-null  float64\n",
      " 1   rh          450342 non-null  float64\n",
      " 2   ws          450342 non-null  float64\n",
      " 3   wd          450342 non-null  int64  \n",
      " 4   pcp         450342 non-null  float64\n",
      " 5   ffmc        450342 non-null  float64\n",
      " 6   dmc         450342 non-null  float64\n",
      " 7   dc          450342 non-null  float64\n",
      " 8   isi         450342 non-null  float64\n",
      " 9   bui         450342 non-null  float64\n",
      " 10  fwi         450342 non-null  float64\n",
      " 11  ros         450339 non-null  float64\n",
      " 12  sfc         450339 non-null  float64\n",
      " 13  tfc         450339 non-null  float64\n",
      " 14  bfc         239132 non-null  float64\n",
      " 15  hfi         450339 non-null  float64\n",
      " 16  cfb         450339 non-null  float64\n",
      " 17  pcuring     425990 non-null  float64\n",
      " 18  greenup     425990 non-null  float64\n",
      " 19  elev        450342 non-null  int64  \n",
      " 20  sfl         450342 non-null  float64\n",
      " 21  cfl         450342 non-null  float64\n",
      " 22  tfc0        450339 non-null  float64\n",
      " 23  sfc0        450339 non-null  float64\n",
      " 24  year        450342 non-null  int64  \n",
      " 25  month       450342 non-null  int64  \n",
      " 26  day         450342 non-null  int64  \n",
      " 27  lat_sin     450342 non-null  float64\n",
      " 28  lat_cos     450342 non-null  float64\n",
      " 29  lon_sin     450342 non-null  float64\n",
      " 30  lon_cos     450342 non-null  float64\n",
      " 31  year_month  450342 non-null  object \n",
      "dtypes: float64(26), int64(5), object(1)\n",
      "memory usage: 109.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform Dataset to TimeSeriesDataset of Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_wildfire_data(df, lat_bins=50, lon_bins=50):\n",
    "    # Create a datetime column\n",
    "    df['date'] = pd.to_datetime(df[['year', 'month', 'day']])\n",
    "    \n",
    "    # Create group_id based on latitude and longitude\n",
    "    df['lat'] = np.arcsin(df['lat_sin'])  # Convert back to latitude\n",
    "    df['lon'] = np.arctan2(df['lon_sin'], df['lon_cos'])  # Convert back to longitude\n",
    "    \n",
    "    df['lat_group'] = pd.cut(df['lat'], bins=lat_bins, labels=False)\n",
    "    df['lon_group'] = pd.cut(df['lon'], bins=lon_bins, labels=False)\n",
    "    df['group_id'] = df['lat_group'].astype(str) + '_' + df['lon_group'].astype(str)\n",
    "    df['group_id'] = pd.factorize(df['group_id'])[0]\n",
    "\n",
    "    return df\n",
    "\n",
    "df = prepare_wildfire_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the data schema\n",
    "static_categoricals=['group_id']\n",
    "static_reals=['elev', 'lat_sin', 'lat_cos', 'lon_sin', 'lon_cos']\n",
    "time_varying_known_reals=['month', 'day']\n",
    "time_varying_unknown_reals=['temp', 'rh', 'ws', 'wd', 'pcp', 'ffmc', 'dmc', 'dc', 'isi', 'bui', \n",
    "                            'ros', 'sfc', 'tfc', 'bfc', 'hfi', 'cfb', 'pcuring', 'greenup', \n",
    "                            'sfl', 'cfl', 'tfc0', 'sfc0']\n",
    "group_ids=['group_id']\n",
    "max_encoder_length=30\n",
    "max_prediction_length=7\n",
    "lat_bins=50\n",
    "lon_bins=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.26.4 in /usr/local/python/3.10.13/lib/python3.10/site-packages (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.26.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy.lib.function_base'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_forecasting\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TimeSeriesDataSet\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_forecasting\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TemporalFusionTransformer\n\u001b[1;32m      5\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/pytorch_forecasting/__init__.py:31\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_forecasting\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      5\u001b[0m     EncoderNormalizer,\n\u001b[1;32m      6\u001b[0m     GroupNormalizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     TimeSeriesDataSet,\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_forecasting\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     12\u001b[0m     MAE,\n\u001b[1;32m     13\u001b[0m     MAPE,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m     QuantileLoss,\n\u001b[1;32m     30\u001b[0m )\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_forecasting\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     32\u001b[0m     GRU,\n\u001b[1;32m     33\u001b[0m     LSTM,\n\u001b[1;32m     34\u001b[0m     AutoRegressiveBaseModel,\n\u001b[1;32m     35\u001b[0m     AutoRegressiveBaseModelWithCovariates,\n\u001b[1;32m     36\u001b[0m     Baseline,\n\u001b[1;32m     37\u001b[0m     BaseModel,\n\u001b[1;32m     38\u001b[0m     BaseModelWithCovariates,\n\u001b[1;32m     39\u001b[0m     DecoderMLP,\n\u001b[1;32m     40\u001b[0m     DeepAR,\n\u001b[1;32m     41\u001b[0m     MultiEmbedding,\n\u001b[1;32m     42\u001b[0m     NBeats,\n\u001b[1;32m     43\u001b[0m     NHiTS,\n\u001b[1;32m     44\u001b[0m     RecurrentNetwork,\n\u001b[1;32m     45\u001b[0m     TemporalFusionTransformer,\n\u001b[1;32m     46\u001b[0m     get_rnn,\n\u001b[1;32m     47\u001b[0m )\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_forecasting\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     49\u001b[0m     apply_to_list,\n\u001b[1;32m     50\u001b[0m     autocorrelation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     59\u001b[0m     unpack_sequence,\n\u001b[1;32m     60\u001b[0m )\n\u001b[1;32m     62\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTimeSeriesDataSet\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGroupNormalizer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munpack_sequence\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    112\u001b[0m ]\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/pytorch_forecasting/models/__init__.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mModels for timeseries forecasting.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_forecasting\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      5\u001b[0m     AutoRegressiveBaseModel,\n\u001b[1;32m      6\u001b[0m     AutoRegressiveBaseModelWithCovariates,\n\u001b[1;32m      7\u001b[0m     BaseModel,\n\u001b[1;32m      8\u001b[0m     BaseModelWithCovariates,\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_forecasting\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbaseline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Baseline\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_forecasting\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeepar\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DeepAR\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/pytorch_forecasting/models/base_model.py:20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunction_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m iterable\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpytorch_optimizer\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy.lib.function_base'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from pytorch_forecasting import TimeSeriesDataSet\n",
    "from pytorch_forecasting.models import TemporalFusionTransformer\n",
    "\n",
    "scaler = StandardScaler()\n",
    "numerical_features = static_reals + time_varying_known_reals + time_varying_unknown_reals\n",
    "train[numerical_features] = scaler.fit_transform(train[numerical_features])\n",
    "test[numerical_features] = scaler.transform(train[numerical_features])\n",
    "\n",
    "# Create the TimeSeriesDataSet\n",
    "dataset = TimeSeriesDataSet(\n",
    "    df,\n",
    "    time_idx=time_idx,\n",
    "    target=target_variable,\n",
    "    group_ids=group_ids,\n",
    "    static_categoricals=static_categoricals,\n",
    "    static_reals=static_reals,\n",
    "    time_varying_known_reals=time_varying_known_reals,\n",
    "    time_varying_unknown_reals=time_varying_unknown_reals,\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    max_prediction_length=max_prediction_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
