{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/engineered_wildfire_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 450342 entries, 0 to 450341\n",
      "Data columns (total 32 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   temp        450342 non-null  float64\n",
      " 1   rh          450342 non-null  float64\n",
      " 2   ws          450342 non-null  float64\n",
      " 3   wd          450342 non-null  int64  \n",
      " 4   pcp         450342 non-null  float64\n",
      " 5   ffmc        450342 non-null  float64\n",
      " 6   dmc         450342 non-null  float64\n",
      " 7   dc          450342 non-null  float64\n",
      " 8   isi         450342 non-null  float64\n",
      " 9   bui         450342 non-null  float64\n",
      " 10  fwi         450342 non-null  float64\n",
      " 11  ros         450339 non-null  float64\n",
      " 12  sfc         450339 non-null  float64\n",
      " 13  tfc         450339 non-null  float64\n",
      " 14  bfc         239132 non-null  float64\n",
      " 15  hfi         450339 non-null  float64\n",
      " 16  cfb         450339 non-null  float64\n",
      " 17  pcuring     425990 non-null  float64\n",
      " 18  greenup     425990 non-null  float64\n",
      " 19  elev        450342 non-null  int64  \n",
      " 20  sfl         450342 non-null  float64\n",
      " 21  cfl         450342 non-null  float64\n",
      " 22  tfc0        450339 non-null  float64\n",
      " 23  sfc0        450339 non-null  float64\n",
      " 24  year        450342 non-null  int64  \n",
      " 25  month       450342 non-null  int64  \n",
      " 26  day         450342 non-null  int64  \n",
      " 27  lat_sin     450342 non-null  float64\n",
      " 28  lat_cos     450342 non-null  float64\n",
      " 29  lon_sin     450342 non-null  float64\n",
      " 30  lon_cos     450342 non-null  float64\n",
      " 31  year_month  450342 non-null  object \n",
      "dtypes: float64(26), int64(5), object(1)\n",
      "memory usage: 109.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform Dataset to TimeSeriesDataset of Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_wildfire_data(df, target_variable='fwi', sequence_length=30, forecast_horizon=7, lat_bins=50, lon_bins=50):\n",
    "    # Create a datetime column\n",
    "    df['date'] = pd.to_datetime(df[['year', 'month', 'day']])\n",
    "    \n",
    "    # Create group_id based on latitude and longitude\n",
    "    df['lat'] = np.arcsin(df['lat_sin'])  # Convert back to latitude\n",
    "    df['lon'] = np.arctan2(df['lon_sin'], df['lon_cos'])  # Convert back to longitude\n",
    "    \n",
    "    df['lat_group'] = pd.cut(df['lat'], bins=lat_bins, labels=False)\n",
    "    df['lon_group'] = pd.cut(df['lon'], bins=lon_bins, labels=False)\n",
    "    df['group_id'] = df['lat_group'].astype(str) + '_' + df['lon_group'].astype(str)\n",
    "    df['group_id'] = pd.factorize(df['group_id'])[0]\n",
    "\n",
    "    return df\n",
    "\n",
    "df = prepare_wildfire_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_variable='fwi'\n",
    "time_idx='time_idx' \n",
    "static_categoricals=['group_id']\n",
    "static_reals=['elev', 'lat_sin', 'lat_cos', 'lon_sin', 'lon_cos']\n",
    "time_varying_known_reals=['month', 'day']\n",
    "time_varying_unknown_reals=['temp', 'rh', 'ws', 'wd', 'pcp', 'ffmc', 'dmc', 'dc', 'isi', 'bui', \n",
    "                            'ros', 'sfc', 'tfc', 'bfc', 'hfi', 'cfb', 'pcuring', 'greenup', \n",
    "                            'sfl', 'cfl', 'tfc0', 'sfc0']\n",
    "group_ids=['group_id']\n",
    "max_encoder_length=30\n",
    "max_prediction_length=7\n",
    "lat_bins=50\n",
    "lon_bins=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from pytorch_forecasting import TimeSeriesDataSet\n",
    "from pytorch_forecasting.models import TemporalFusionTransformer\n",
    "\n",
    "scaler = StandardScaler()\n",
    "numerical_features = static_reals + time_varying_known_reals + time_varying_unknown_reals\n",
    "df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
    "\n",
    "# Create the TimeSeriesDataSet\n",
    "dataset = TimeSeriesDataSet(\n",
    "    df,\n",
    "    time_idx=time_idx,\n",
    "    target=target_variable,\n",
    "    group_ids=group_ids,\n",
    "    static_categoricals=static_categoricals,\n",
    "    static_reals=static_reals,\n",
    "    time_varying_known_reals=time_varying_known_reals,\n",
    "    time_varying_unknown_reals=time_varying_unknown_reals,\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    max_prediction_length=max_prediction_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
