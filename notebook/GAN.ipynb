{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, LSTM, RepeatVector, TimeDistributed, Flatten, Reshape\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define the generator\n",
    "def build_generator(latent_dim, time_steps, features):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='relu', input_dim=latent_dim))\n",
    "    model.add(RepeatVector(time_steps))\n",
    "    model.add(LSTM(128, activation='relu', return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(features, activation='sigmoid')))\n",
    "    return model\n",
    "\n",
    "# Define the discriminator\n",
    "def build_discriminator(time_steps, features):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, input_shape=(time_steps, features), return_sequences=True))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "# Build and compile the GAN\n",
    "latent_dim = 100\n",
    "time_steps = train_sequences.shape[1]\n",
    "features = train_sequences.shape[2]\n",
    "\n",
    "generator = build_generator(latent_dim, time_steps, features)\n",
    "discriminator = build_discriminator(time_steps, features)\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "discriminator.trainable = False\n",
    "gan_input = Input(shape=(latent_dim,))\n",
    "generated_sequence = generator(gan_input)\n",
    "gan_output = discriminator(generated_sequence)\n",
    "gan = Model(gan_input, gan_output)\n",
    "gan.compile(loss='binary_crossentropy', optimizer=Adam())\n",
    "\n",
    "# Training the GAN\n",
    "def train_gan(gan, generator, discriminator, epochs, batch_size, train_sequences, latent_dim):\n",
    "    for epoch in range(epochs):\n",
    "        # Train discriminator\n",
    "        idx = np.random.randint(0, train_sequences.shape[0], batch_size)\n",
    "        real_sequences = train_sequences[idx]\n",
    "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        generated_sequences = generator.predict(noise)\n",
    "        \n",
    "        d_loss_real = discriminator.train_on_batch(real_sequences, np.ones((batch_size, 1)))\n",
    "        d_loss_fake = discriminator.train_on_batch(generated_sequences, np.zeros((batch_size, 1)))\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "        \n",
    "        # Train generator\n",
    "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        valid_y = np.array([1] * batch_size)\n",
    "        g_loss = gan.train_on_batch(noise, valid_y)\n",
    "        \n",
    "        print(f\"{epoch+1}/{epochs} [D loss: {d_loss[0]} | D accuracy: {d_loss[1]}] [G loss: {g_loss}]\")\n",
    "\n",
    "train_gan(gan, generator, discriminator, epochs=1000, batch_size=32, train_sequences=train_sequences, latent_dim=latent_dim)\n",
    "\n",
    "# Generate and plot new wildfire simulations\n",
    "gan_simulations = generate_simulation(generator, num_samples=5)\n",
    "\n",
    "for i, sim in enumerate(gan_simulations):\n",
    "    plt.figure(figsize=(14, 5))\n",
    "    plt.plot(sim, label=f'Simulation {i+1}')\n",
    "    plt.legend()\n",
    "    plt.title('Generated Wildfire Simulation with GAN')\n",
    "    plt.xlabel('Time Steps')\n",
    "    plt.ylabel('Normalized Feature Values')\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
