{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8844421,"sourceType":"datasetVersion","datasetId":5323261}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2024-07-10T02:51:01.820568Z","iopub.execute_input":"2024-07-10T02:51:01.821288Z","iopub.status.idle":"2024-07-10T02:51:02.793728Z","shell.execute_reply.started":"2024-07-10T02:51:01.821237Z","shell.execute_reply":"2024-07-10T02:51:02.792745Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/wildfiredata/engineered_wildfire_data.csv')","metadata":{"execution":{"iopub.status.busy":"2024-07-10T02:51:02.795553Z","iopub.execute_input":"2024-07-10T02:51:02.796444Z","iopub.status.idle":"2024-07-10T02:51:06.708442Z","shell.execute_reply.started":"2024-07-10T02:51:02.796407Z","shell.execute_reply":"2024-07-10T02:51:06.707618Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2024-07-10T02:51:06.709614Z","iopub.execute_input":"2024-07-10T02:51:06.709956Z","iopub.status.idle":"2024-07-10T02:51:06.798294Z","shell.execute_reply.started":"2024-07-10T02:51:06.709925Z","shell.execute_reply":"2024-07-10T02:51:06.797413Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 450342 entries, 0 to 450341\nData columns (total 32 columns):\n #   Column      Non-Null Count   Dtype  \n---  ------      --------------   -----  \n 0   temp        450342 non-null  float64\n 1   rh          450342 non-null  float64\n 2   ws          450342 non-null  float64\n 3   wd          450342 non-null  int64  \n 4   pcp         450342 non-null  float64\n 5   ffmc        450342 non-null  float64\n 6   dmc         450342 non-null  float64\n 7   dc          450342 non-null  float64\n 8   isi         450342 non-null  float64\n 9   bui         450342 non-null  float64\n 10  fwi         450342 non-null  float64\n 11  ros         450339 non-null  float64\n 12  sfc         450339 non-null  float64\n 13  tfc         450339 non-null  float64\n 14  bfc         239132 non-null  float64\n 15  hfi         450339 non-null  float64\n 16  cfb         450339 non-null  float64\n 17  pcuring     425990 non-null  float64\n 18  greenup     425990 non-null  float64\n 19  elev        450342 non-null  int64  \n 20  sfl         450342 non-null  float64\n 21  cfl         450342 non-null  float64\n 22  tfc0        450339 non-null  float64\n 23  sfc0        450339 non-null  float64\n 24  year        450342 non-null  int64  \n 25  month       450342 non-null  int64  \n 26  day         450342 non-null  int64  \n 27  lat_sin     450342 non-null  float64\n 28  lat_cos     450342 non-null  float64\n 29  lon_sin     450342 non-null  float64\n 30  lon_cos     450342 non-null  float64\n 31  year_month  450342 non-null  object \ndtypes: float64(26), int64(5), object(1)\nmemory usage: 109.9+ MB\n","output_type":"stream"}]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-10T02:51:06.800798Z","iopub.execute_input":"2024-07-10T02:51:06.801488Z","iopub.status.idle":"2024-07-10T02:51:06.832925Z","shell.execute_reply.started":"2024-07-10T02:51:06.801454Z","shell.execute_reply":"2024-07-10T02:51:06.832034Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"       temp        rh        ws   wd    pcp    ffmc      dmc       dc     isi  \\\n0 -1.006741  2.094934 -0.649149  320  0.430  82.976   30.078  161.161   2.680   \n1  0.423696  0.992790 -0.700308  145  1.237  68.466    0.000  294.020   0.977   \n2  0.226618  1.122454 -0.867970   30  0.591  88.685   55.743  202.448   5.536   \n3  1.366794 -1.665321 -0.843150  271  0.000  98.652  290.568  841.230  22.181   \n4  1.170139  0.020311 -0.000958   50  0.001  91.660   18.664  102.620  10.972   \n\n       bui  ...  tfc0  sfc0  year  month  day   lat_sin   lat_cos   lon_sin  \\\n0   41.018  ...  0.35  0.35  2020      6    2  0.883899  0.467678 -0.311904   \n1    0.000  ...  0.10  0.10  2020      6   11  0.879890  0.475177 -0.268096   \n2   66.032  ...  1.36  1.36  2020      6   20  0.736971  0.675925 -0.939322   \n3  311.848  ...  0.35  0.35  2020      6   22  0.535709  0.844403 -0.934801   \n4   25.660  ...  0.35  0.35  2020      6   13  0.551529  0.834155 -0.999729   \n\n    lon_cos  year_month  \n0 -0.950114      2020-6  \n1 -0.963392      2020-6  \n2  0.343037      2020-6  \n3 -0.355172      2020-6  \n4 -0.023267      2020-6  \n\n[5 rows x 32 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>temp</th>\n      <th>rh</th>\n      <th>ws</th>\n      <th>wd</th>\n      <th>pcp</th>\n      <th>ffmc</th>\n      <th>dmc</th>\n      <th>dc</th>\n      <th>isi</th>\n      <th>bui</th>\n      <th>...</th>\n      <th>tfc0</th>\n      <th>sfc0</th>\n      <th>year</th>\n      <th>month</th>\n      <th>day</th>\n      <th>lat_sin</th>\n      <th>lat_cos</th>\n      <th>lon_sin</th>\n      <th>lon_cos</th>\n      <th>year_month</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1.006741</td>\n      <td>2.094934</td>\n      <td>-0.649149</td>\n      <td>320</td>\n      <td>0.430</td>\n      <td>82.976</td>\n      <td>30.078</td>\n      <td>161.161</td>\n      <td>2.680</td>\n      <td>41.018</td>\n      <td>...</td>\n      <td>0.35</td>\n      <td>0.35</td>\n      <td>2020</td>\n      <td>6</td>\n      <td>2</td>\n      <td>0.883899</td>\n      <td>0.467678</td>\n      <td>-0.311904</td>\n      <td>-0.950114</td>\n      <td>2020-6</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.423696</td>\n      <td>0.992790</td>\n      <td>-0.700308</td>\n      <td>145</td>\n      <td>1.237</td>\n      <td>68.466</td>\n      <td>0.000</td>\n      <td>294.020</td>\n      <td>0.977</td>\n      <td>0.000</td>\n      <td>...</td>\n      <td>0.10</td>\n      <td>0.10</td>\n      <td>2020</td>\n      <td>6</td>\n      <td>11</td>\n      <td>0.879890</td>\n      <td>0.475177</td>\n      <td>-0.268096</td>\n      <td>-0.963392</td>\n      <td>2020-6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.226618</td>\n      <td>1.122454</td>\n      <td>-0.867970</td>\n      <td>30</td>\n      <td>0.591</td>\n      <td>88.685</td>\n      <td>55.743</td>\n      <td>202.448</td>\n      <td>5.536</td>\n      <td>66.032</td>\n      <td>...</td>\n      <td>1.36</td>\n      <td>1.36</td>\n      <td>2020</td>\n      <td>6</td>\n      <td>20</td>\n      <td>0.736971</td>\n      <td>0.675925</td>\n      <td>-0.939322</td>\n      <td>0.343037</td>\n      <td>2020-6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.366794</td>\n      <td>-1.665321</td>\n      <td>-0.843150</td>\n      <td>271</td>\n      <td>0.000</td>\n      <td>98.652</td>\n      <td>290.568</td>\n      <td>841.230</td>\n      <td>22.181</td>\n      <td>311.848</td>\n      <td>...</td>\n      <td>0.35</td>\n      <td>0.35</td>\n      <td>2020</td>\n      <td>6</td>\n      <td>22</td>\n      <td>0.535709</td>\n      <td>0.844403</td>\n      <td>-0.934801</td>\n      <td>-0.355172</td>\n      <td>2020-6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.170139</td>\n      <td>0.020311</td>\n      <td>-0.000958</td>\n      <td>50</td>\n      <td>0.001</td>\n      <td>91.660</td>\n      <td>18.664</td>\n      <td>102.620</td>\n      <td>10.972</td>\n      <td>25.660</td>\n      <td>...</td>\n      <td>0.35</td>\n      <td>0.35</td>\n      <td>2020</td>\n      <td>6</td>\n      <td>13</td>\n      <td>0.551529</td>\n      <td>0.834155</td>\n      <td>-0.999729</td>\n      <td>-0.023267</td>\n      <td>2020-6</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 32 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-07-10T02:51:06.834042Z","iopub.execute_input":"2024-07-10T02:51:06.834347Z","iopub.status.idle":"2024-07-10T02:51:06.899495Z","shell.execute_reply.started":"2024-07-10T02:51:06.834322Z","shell.execute_reply":"2024-07-10T02:51:06.898560Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"temp               0\nrh                 0\nws                 0\nwd                 0\npcp                0\nffmc               0\ndmc                0\ndc                 0\nisi                0\nbui                0\nfwi                0\nros                3\nsfc                3\ntfc                3\nbfc           211210\nhfi                3\ncfb                3\npcuring        24352\ngreenup        24352\nelev               0\nsfl                0\ncfl                0\ntfc0               3\nsfc0               3\nyear               0\nmonth              0\nday                0\nlat_sin            0\nlat_cos            0\nlon_sin            0\nlon_cos            0\nyear_month         0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df = df.sort_values(['year', 'month', 'day'], ascending=True)","metadata":{"execution":{"iopub.status.busy":"2024-07-10T02:51:06.900708Z","iopub.execute_input":"2024-07-10T02:51:06.901057Z","iopub.status.idle":"2024-07-10T02:51:07.004685Z","shell.execute_reply.started":"2024-07-10T02:51:06.901025Z","shell.execute_reply":"2024-07-10T02:51:07.003896Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# df.fillna(method='ffill', inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-07-10T02:51:07.005740Z","iopub.execute_input":"2024-07-10T02:51:07.006016Z","iopub.status.idle":"2024-07-10T02:51:07.009826Z","shell.execute_reply.started":"2024-07-10T02:51:07.005992Z","shell.execute_reply":"2024-07-10T02:51:07.008961Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"primary_features = [\n    'temp',    # Temperature\n    'rh',      # Relative Humidity\n    'ws',      # Wind Speed\n    'wd',      # Wind Direction\n    'ffmc',    # Fine Fuel Moisture Code\n    'dmc',     # Duff Moisture Code\n    'dc',      # Drought Code\n    'isi',     # Initial Spread Index\n    'bui',     # Buildup Index\n    'fwi',     # Fire Weather Index\n    'ros',     # Rate of Spread\n    'sfc',     # Surface Fuel Consumption\n    'tfc',     # Total Fuel Consumption\n    'hfi',     # Head Fire Intensity\n    'pcuring', # Percent Curing (if available)\n    'elev',    # Elevation\n    'sfl',     # Surface Fuel Load (if this represents available surface fuels)\n    'cfl'      # Crown Fuel Load\n]","metadata":{"execution":{"iopub.status.busy":"2024-07-10T02:51:07.010795Z","iopub.execute_input":"2024-07-10T02:51:07.011077Z","iopub.status.idle":"2024-07-10T02:51:07.020352Z","shell.execute_reply.started":"2024-07-10T02:51:07.011053Z","shell.execute_reply":"2024-07-10T02:51:07.019545Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Time-based features\ntime_features = ['month_sin', 'month_cos', 'day_sin', 'day_cos', 'age']\n# Note: 'year_month' is omitted as it's likely redundant with 'year' and 'month'\n\n# Derived features\nderived_features = [\n    'temp_lag_1',     # Temperature from previous time step\n    'ws_lag_1',       # Wind speed from previous time step\n    'rh_lag_1',       # Relative humidity from previous time step\n    'ffmc_lag_1',     # FFMC from previous time step\n    'isi_lag_1',      # ISI from previous time step\n    'fwi_lag_1',      # FWI from previous time step\n    'drought_index',  # Composite drought index (e.g., (dc + dmc) / 2)\n  #  'day_of_year',    # Calculated from year, month, day\n    'season'          # Derived from month (e.g., Spring, Summer, Fall, Winter)\n]","metadata":{"execution":{"iopub.status.busy":"2024-07-10T02:51:07.021462Z","iopub.execute_input":"2024-07-10T02:51:07.021780Z","iopub.status.idle":"2024-07-10T02:51:07.030195Z","shell.execute_reply.started":"2024-07-10T02:51:07.021749Z","shell.execute_reply":"2024-07-10T02:51:07.029241Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Combine all features\nall_features = primary_features + time_features + derived_features","metadata":{"execution":{"iopub.status.busy":"2024-07-10T02:51:07.033571Z","iopub.execute_input":"2024-07-10T02:51:07.033863Z","iopub.status.idle":"2024-07-10T02:51:07.040699Z","shell.execute_reply.started":"2024-07-10T02:51:07.033840Z","shell.execute_reply":"2024-07-10T02:51:07.039892Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def derive_features(df):\n    # Ensure datetime index\n    df['date'] = pd.to_datetime(df['year'].astype(str) + '-' + df['month'].astype(str) + '-' + df['day'].astype(str))\n    df.set_index('date', inplace=True)\n    \n    # Create day of year\n#     df['day_of_year'] = df.index.dayofyear\n    \n    # Create season\n    df['season'] = pd.cut(df['month'], bins=[0, 3, 6, 9, 12], labels=['Winter', 'Spring', 'Summer', 'Fall'])\n    \n    # Create lag features\n    for feature in ['temp', 'ws', 'rh', 'ffmc', 'isi', 'fwi']:\n        df[f'{feature}_lag_1'] = df[feature].shift(1)\n    \n    # Create drought index\n    df['drought_index'] = (df['dc'] + df['dmc']) / 2\n    \n    return df\n\n# Apply the function to your dataframe\ndf = derive_features(df)","metadata":{"execution":{"iopub.status.busy":"2024-07-10T02:51:07.041767Z","iopub.execute_input":"2024-07-10T02:51:07.042082Z","iopub.status.idle":"2024-07-10T02:51:07.978983Z","shell.execute_reply.started":"2024-07-10T02:51:07.042051Z","shell.execute_reply":"2024-07-10T02:51:07.978016Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def add_fourier_features(df):\n    # Create cyclic features using sine and cosine transformations\n    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n    df['day_sin'] = np.sin(2 * np.pi * df['day'] / 31)\n    df['day_cos'] = np.cos(2 * np.pi * df['day'] / 31)\n    return df","metadata":{"execution":{"iopub.status.busy":"2024-07-10T02:51:07.980210Z","iopub.execute_input":"2024-07-10T02:51:07.980532Z","iopub.status.idle":"2024-07-10T02:51:07.986256Z","shell.execute_reply.started":"2024-07-10T02:51:07.980506Z","shell.execute_reply":"2024-07-10T02:51:07.985397Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def add_age_feature(df):\n    df['age'] = (df.index - df.index.min()).days\n    return df","metadata":{"execution":{"iopub.status.busy":"2024-07-10T02:51:07.987484Z","iopub.execute_input":"2024-07-10T02:51:07.988201Z","iopub.status.idle":"2024-07-10T02:51:07.996029Z","shell.execute_reply.started":"2024-07-10T02:51:07.988169Z","shell.execute_reply":"2024-07-10T02:51:07.995219Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"df = add_fourier_features(df)\ndf = add_age_feature(df)","metadata":{"execution":{"iopub.status.busy":"2024-07-10T02:51:07.999009Z","iopub.execute_input":"2024-07-10T02:51:07.999288Z","iopub.status.idle":"2024-07-10T02:51:08.048655Z","shell.execute_reply.started":"2024-07-10T02:51:07.999258Z","shell.execute_reply":"2024-07-10T02:51:08.047854Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"df = df.drop(columns=['year', 'month', 'day'])","metadata":{"execution":{"iopub.status.busy":"2024-07-10T02:51:08.049832Z","iopub.execute_input":"2024-07-10T02:51:08.050240Z","iopub.status.idle":"2024-07-10T02:51:08.128799Z","shell.execute_reply.started":"2024-07-10T02:51:08.050208Z","shell.execute_reply":"2024-07-10T02:51:08.127780Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"final_df = pd.concat([df[all_features], df['cfb']], axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-07-10T02:51:08.130185Z","iopub.execute_input":"2024-07-10T02:51:08.130576Z","iopub.status.idle":"2024-07-10T02:51:08.307743Z","shell.execute_reply.started":"2024-07-10T02:51:08.130543Z","shell.execute_reply":"2024-07-10T02:51:08.306964Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"final_df.info()","metadata":{"execution":{"iopub.status.busy":"2024-07-10T02:51:08.309017Z","iopub.execute_input":"2024-07-10T02:51:08.309509Z","iopub.status.idle":"2024-07-10T02:51:08.350449Z","shell.execute_reply.started":"2024-07-10T02:51:08.309473Z","shell.execute_reply":"2024-07-10T02:51:08.349575Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nDatetimeIndex: 450342 entries, 2020-03-01 to 2023-11-04\nData columns (total 32 columns):\n #   Column         Non-Null Count   Dtype   \n---  ------         --------------   -----   \n 0   temp           450342 non-null  float64 \n 1   rh             450342 non-null  float64 \n 2   ws             450342 non-null  float64 \n 3   wd             450342 non-null  int64   \n 4   ffmc           450342 non-null  float64 \n 5   dmc            450342 non-null  float64 \n 6   dc             450342 non-null  float64 \n 7   isi            450342 non-null  float64 \n 8   bui            450342 non-null  float64 \n 9   fwi            450342 non-null  float64 \n 10  ros            450339 non-null  float64 \n 11  sfc            450339 non-null  float64 \n 12  tfc            450339 non-null  float64 \n 13  hfi            450339 non-null  float64 \n 14  pcuring        425990 non-null  float64 \n 15  elev           450342 non-null  int64   \n 16  sfl            450342 non-null  float64 \n 17  cfl            450342 non-null  float64 \n 18  month_sin      450342 non-null  float64 \n 19  month_cos      450342 non-null  float64 \n 20  day_sin        450342 non-null  float64 \n 21  day_cos        450342 non-null  float64 \n 22  age            450342 non-null  int64   \n 23  temp_lag_1     450341 non-null  float64 \n 24  ws_lag_1       450341 non-null  float64 \n 25  rh_lag_1       450341 non-null  float64 \n 26  ffmc_lag_1     450341 non-null  float64 \n 27  isi_lag_1      450341 non-null  float64 \n 28  fwi_lag_1      450341 non-null  float64 \n 29  drought_index  450342 non-null  float64 \n 30  season         450342 non-null  category\n 31  cfb            450339 non-null  float64 \ndtypes: category(1), float64(28), int64(3)\nmemory usage: 110.4 MB\n","output_type":"stream"}]},{"cell_type":"code","source":"lags_sequence = [1,2,3,4,5,6,7]","metadata":{"execution":{"iopub.status.busy":"2024-07-10T02:51:08.351763Z","iopub.execute_input":"2024-07-10T02:51:08.352425Z","iopub.status.idle":"2024-07-10T02:51:08.357036Z","shell.execute_reply.started":"2024-07-10T02:51:08.352388Z","shell.execute_reply":"2024-07-10T02:51:08.356042Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# input_size = X_train.shape[2]  # number of features\n# prediction_length = 24 # Predicting cfb for the next time step\n# #context_length = X_train.shape[1]  # Same as sequence_length\n# context_length = X_train.shape[1] - max(lags_sequence) - prediction_length","metadata":{"execution":{"iopub.status.busy":"2024-07-10T02:51:08.358602Z","iopub.execute_input":"2024-07-10T02:51:08.358954Z","iopub.status.idle":"2024-07-10T02:51:08.367769Z","shell.execute_reply.started":"2024-07-10T02:51:08.358923Z","shell.execute_reply":"2024-07-10T02:51:08.366911Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoformerConfig, AutoformerModel\n\nconfig = AutoformerConfig(\n    input_size=35,  # number of input features\n    context_length=48,  # context length excluding lags\n    prediction_length=24,  # number of time steps to predict\n    num_time_features=len(time_features),  # number of time features\n#     num_static_real_features=1,  # number of static real features\n #   num_dynamic_real_features=len(all_features) - len(time_features),  # number of dynamic real features\n    d_model=64,\n    encoder_layers=2,\n    decoder_layers=2,\n    encoder_attention_heads=2,\n    decoder_attention_heads=2,\n    encoder_ffn_dim=128,\n    decoder_ffn_dim=128,\n    lags_sequence=lags_sequence\n)\n\nmodel = AutoformerModel(config)","metadata":{"execution":{"iopub.status.busy":"2024-07-10T02:51:08.368979Z","iopub.execute_input":"2024-07-10T02:51:08.369294Z","iopub.status.idle":"2024-07-10T02:51:14.068665Z","shell.execute_reply.started":"2024-07-10T02:51:08.369238Z","shell.execute_reply":"2024-07-10T02:51:14.067826Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Use the context and prediction lengths from the configuration\ncontext_length = config.context_length\nprediction_length = config.prediction_length\nlags_sequence = config.lags_sequence","metadata":{"execution":{"iopub.status.busy":"2024-07-10T02:51:14.069909Z","iopub.execute_input":"2024-07-10T02:51:14.070876Z","iopub.status.idle":"2024-07-10T02:51:14.075195Z","shell.execute_reply.started":"2024-07-10T02:51:14.070840Z","shell.execute_reply":"2024-07-10T02:51:14.074204Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\n\ndef prepare_data(df, target_column='cfb', test_size=0.2):\n    # Ensure the dataframe is sorted by date\n    df = df.sort_index()\n\n    # Separate the target column from the features\n    features = df.drop(columns=[target_column])\n    target = df[target_column]\n\n    # Split the data into training and testing sets\n    train_features, test_features, train_target, test_target = train_test_split(\n        features, target, test_size=test_size, shuffle=False\n    )\n\n    # Identify categorical and numerical features\n    categorical_features = ['season']\n    numeric_features = train_features.select_dtypes(include=['float64', 'int64']).columns.tolist()\n    \n #   time_features = ['year', 'month', 'day', 'day_of_year']\n    numeric_features = [f for f in numeric_features if f not in time_features]\n\n    # Create the preprocessing pipelines for both numeric and categorical data\n    numeric_transformer = StandardScaler()\n    categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n\n    # Combine the transformers into a preprocessor\n    preprocessor = ColumnTransformer(\n        transformers=[\n            ('num', numeric_transformer, numeric_features),\n            ('cat', categorical_transformer, categorical_features),\n            ('time', 'passthrough', time_features)  # passthrough time features\n        ]\n    )\n\n    # Apply the transformations to train and test data\n    train_features_scaled = preprocessor.fit_transform(train_features)\n    test_features_scaled = preprocessor.transform(test_features)\n\n    # Reconstruct DataFrame from the transformed data\n    numeric_columns = preprocessor.transformers_[0][2]\n    categorical_columns = preprocessor.transformers_[1][1].get_feature_names_out(categorical_features)\n    time_columns = preprocessor.transformers_[2][2]\n    \n    all_columns = list(numeric_columns) + list(categorical_columns) + list(time_columns)\n    \n    # Convert the transformed data back to DataFrame\n    train_features_scaled_df = pd.DataFrame(train_features_scaled, index=train_features.index, columns=all_columns)\n    test_features_scaled_df = pd.DataFrame(test_features_scaled, index=test_features.index, columns=all_columns)\n    print(train_features_scaled_df)\n    # Add the target column back to the scaled data\n    train_scaled = train_features_scaled_df.copy()\n    train_scaled[target_column] = train_target\n    test_scaled = test_features_scaled_df.copy()\n    test_scaled[target_column] = test_target\n\n    # Function to create sequences\n    def create_sequences(data, context_length, prediction_length, lags_sequence):\n        X, y = [], []\n        past_length = context_length + max(lags_sequence)\n        total_length = past_length + prediction_length\n\n        for i in range(len(data) - total_length + 1):\n            # Extract past values (context + lags)\n            past_values = data.iloc[i:i + past_length].values\n            X.append(past_values)\n\n            # Extract future values (predictions)\n            future_values = data.iloc[i + past_length:i + total_length].values\n            y.append(future_values)\n\n        return np.array(X), np.array(y)\n    print('time features: ', time_columns)\n    time_feature_indices = [train_scaled.columns.get_loc(col) for col in time_columns]\n    X_train, y_train = create_sequences(train_scaled, context_length, prediction_length, lags_sequence)\n    X_test, y_test = create_sequences(test_scaled, context_length, prediction_length, lags_sequence)\n\n    return X_train, y_train, X_test, y_test, time_feature_indices\n\n# Prepare the data\nX_train, y_train, X_test, y_test, time_feature_indices = prepare_data(final_df)","metadata":{"execution":{"iopub.status.busy":"2024-07-10T02:51:14.076764Z","iopub.execute_input":"2024-07-10T02:51:14.077309Z","iopub.status.idle":"2024-07-10T02:52:26.679435Z","shell.execute_reply.started":"2024-07-10T02:51:14.077274Z","shell.execute_reply":"2024-07-10T02:52:26.678622Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"                temp        rh        ws        wd      ffmc       dmc  \\\ndate                                                                     \n2020-03-01  0.169331  0.999267  1.725997  0.737452 -0.160303 -0.828024   \n2020-03-01 -1.392263 -0.420849  2.855663  1.053733 -1.057628 -1.022287   \n2020-03-01 -0.925501 -0.162646  0.697408  0.737452  0.068199 -0.752206   \n2020-03-01 -1.189209  0.353760  0.854368  1.159160 -0.112282 -0.928488   \n2020-03-01 -0.212340  0.353760  1.181042  1.475441 -0.675485 -0.173166   \n...              ...       ...       ...       ...       ...       ...   \n2023-01-24 -2.075024  0.353760 -0.250357 -2.109077 -0.622241 -1.085546   \n2023-01-24 -1.710516  0.160108 -0.007321 -2.109077 -0.556084 -1.076072   \n2023-01-24 -1.090737  0.547412  0.973823  1.370014 -4.317738 -1.002084   \n2023-01-25 -0.080704  3.258541  3.475067 -0.211391 -5.786535 -0.715961   \n2023-01-25 -2.362586  1.967527  1.077714  1.275129 -3.677206 -0.587229   \n\n                  dc       isi       bui       fwi  ...  drought_index  \\\ndate                                                ...                  \n2020-03-01 -1.122785 -0.063147 -0.919354 -0.545012  ...      -1.085551   \n2020-03-01 -1.446858 -0.430068 -1.173835 -1.136912  ...      -1.386233   \n2020-03-01  0.017578 -0.106032 -0.726301 -0.365434  ...      -0.199306   \n2020-03-01 -1.595116 -0.211484 -1.122967 -0.932333  ...      -1.472151   \n2020-03-01  0.089224 -0.479194 -0.072440 -0.401156  ...       0.018713   \n...              ...       ...       ...       ...  ...            ...   \n2023-01-24 -1.712303 -0.608408 -1.274195 -1.406653  ...      -1.605420   \n2023-01-24 -1.712303 -0.563523 -1.274195 -1.401732  ...      -1.602741   \n2023-01-24 -0.998913 -0.851796 -1.128290 -1.407532  ...      -1.040816   \n2023-01-25 -0.134934 -0.870598 -0.686060 -1.329848  ...      -0.304721   \n2023-01-25 -0.756684 -0.827633 -0.624006 -1.220132  ...      -0.739844   \n\n            season_Fall  season_Spring  season_Summer  season_Winter  \\\ndate                                                                   \n2020-03-01          0.0            0.0            0.0            1.0   \n2020-03-01          0.0            0.0            0.0            1.0   \n2020-03-01          0.0            0.0            0.0            1.0   \n2020-03-01          0.0            0.0            0.0            1.0   \n2020-03-01          0.0            0.0            0.0            1.0   \n...                 ...            ...            ...            ...   \n2023-01-24          0.0            0.0            0.0            1.0   \n2023-01-24          0.0            0.0            0.0            1.0   \n2023-01-24          0.0            0.0            0.0            1.0   \n2023-01-25          0.0            0.0            0.0            1.0   \n2023-01-25          0.0            0.0            0.0            1.0   \n\n            month_sin     month_cos   day_sin   day_cos     age  \ndate                                                             \n2020-03-01        1.0  6.123234e-17  0.201299  0.979530     0.0  \n2020-03-01        1.0  6.123234e-17  0.201299  0.979530     0.0  \n2020-03-01        1.0  6.123234e-17  0.201299  0.979530     0.0  \n2020-03-01        1.0  6.123234e-17  0.201299  0.979530     0.0  \n2020-03-01        1.0  6.123234e-17  0.201299  0.979530     0.0  \n...               ...           ...       ...       ...     ...  \n2023-01-24        0.5  8.660254e-01 -0.988468  0.151428  1059.0  \n2023-01-24        0.5  8.660254e-01 -0.988468  0.151428  1059.0  \n2023-01-24        0.5  8.660254e-01 -0.988468  0.151428  1059.0  \n2023-01-25        0.5  8.660254e-01 -0.937752  0.347305  1060.0  \n2023-01-25        0.5  8.660254e-01 -0.937752  0.347305  1060.0  \n\n[360273 rows x 34 columns]\ntime features:  ['month_sin', 'month_cos', 'day_sin', 'day_cos', 'age']\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"Shape of X_train:\", X_train.shape)\nprint(\"Shape of y_train:\", y_train.shape)\nprint(\"Shape of X_test:\", X_test.shape)\nprint(\"Shape of y_test:\", y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2024-07-10T02:52:26.680559Z","iopub.execute_input":"2024-07-10T02:52:26.680839Z","iopub.status.idle":"2024-07-10T02:52:26.686101Z","shell.execute_reply.started":"2024-07-10T02:52:26.680814Z","shell.execute_reply":"2024-07-10T02:52:26.685240Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Shape of X_train: (360195, 55, 35)\nShape of y_train: (360195, 24, 35)\nShape of X_test: (89991, 55, 35)\nShape of y_test: (89991, 24, 35)\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch.utils.data import DataLoader, TensorDataset\nimport torch\n\n# Convert data to PyTorch tensors and create DataLoaders\ntrain_dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\ntest_dataset = TensorDataset(torch.FloatTensor(X_test), torch.FloatTensor(y_test))\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-07-10T02:52:26.687262Z","iopub.execute_input":"2024-07-10T02:52:26.687573Z","iopub.status.idle":"2024-07-10T02:52:28.205294Z","shell.execute_reply.started":"2024-07-10T02:52:26.687543Z","shell.execute_reply":"2024-07-10T02:52:28.204220Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"config.context_length","metadata":{"execution":{"iopub.status.busy":"2024-07-10T02:52:28.206881Z","iopub.execute_input":"2024-07-10T02:52:28.207270Z","iopub.status.idle":"2024-07-10T02:52:28.216940Z","shell.execute_reply.started":"2024-07-10T02:52:28.207219Z","shell.execute_reply":"2024-07-10T02:52:28.215931Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"48"},"metadata":{}}]},{"cell_type":"code","source":"lags_sequence","metadata":{"execution":{"iopub.status.busy":"2024-07-10T02:52:28.218231Z","iopub.execute_input":"2024-07-10T02:52:28.218792Z","iopub.status.idle":"2024-07-10T02:52:28.228894Z","shell.execute_reply.started":"2024-07-10T02:52:28.218759Z","shell.execute_reply":"2024-07-10T02:52:28.228234Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"[1, 2, 3, 4, 5, 6, 7]"},"metadata":{}}]},{"cell_type":"code","source":"len(all_features) - len(time_features) - 3","metadata":{"execution":{"iopub.status.busy":"2024-07-10T02:52:28.230145Z","iopub.execute_input":"2024-07-10T02:52:28.231101Z","iopub.status.idle":"2024-07-10T02:52:28.240052Z","shell.execute_reply.started":"2024-07-10T02:52:28.231070Z","shell.execute_reply":"2024-07-10T02:52:28.239278Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"23"},"metadata":{}}]},{"cell_type":"code","source":"def create_past_observed_mask(values):\n    # Create a mask where 1 indicates observed values and 0 indicates missing values (NaNs)\n    mask = ~torch.isnan(values)\n    return mask\n\ndef create_future_observed_mask(values):\n    # Create a mask where 1 indicates observed values and 0 indicates missing values (NaNs)\n    mask = ~torch.isnan(values)\n    return mask","metadata":{"execution":{"iopub.status.busy":"2024-07-10T02:52:28.245627Z","iopub.execute_input":"2024-07-10T02:52:28.245961Z","iopub.status.idle":"2024-07-10T02:52:28.251870Z","shell.execute_reply.started":"2024-07-10T02:52:28.245928Z","shell.execute_reply":"2024-07-10T02:52:28.250613Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# Linear layer to project the output to the desired dimension\nprojection_layer = torch.nn.Linear(320, config.input_size)","metadata":{"execution":{"iopub.status.busy":"2024-07-10T02:52:28.254181Z","iopub.execute_input":"2024-07-10T02:52:28.254591Z","iopub.status.idle":"2024-07-10T02:52:28.263018Z","shell.execute_reply.started":"2024-07-10T02:52:28.254558Z","shell.execute_reply":"2024-07-10T02:52:28.262176Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# Train the model\nfrom torch.optim import Adam\nfrom torch.nn import MSELoss\nimport torch\n\noptimizer = Adam(list(model.parameters()) + list(projection_layer.parameters()), lr=1e-3)\ncriterion = MSELoss()\n\nnum_epochs = 100\nbatch_size = 32\n\n# Helper function to prepare input features\ndef prepare_inputs(x, y, context_length, prediction_length, lags_sequence):\n    batch_size = x.size(0)\n    past_length = context_length + max(lags_sequence)\n    \n    past_values = x[:, :past_length, :]\n    past_time_features = x[:, :, time_feature_indices]\n    \n    # Create past_observed_mask\n    past_observed_mask = create_past_observed_mask(past_values)\n\n    # Replace NaNs in past_values with zeros\n    past_values = torch.nan_to_num(past_values)\n    \n    # Prepare future values from the context\n    future_values = y\n    future_time_features = y[:, :, time_feature_indices]\n\n#     # Create future_observed_mask\n#     future_observed_mask = create_future_observed_mask(future_values)\n\n#     # Replace NaNs in future_values with zeros\n#     future_values = torch.nan_to_num(future_values)\n    \n    # Prepare static real features (assuming no static features here, but can be modified as needed)\n#     static_real_features = None\n    \n    return past_values, past_time_features, past_observed_mask, future_values, future_time_features","metadata":{"execution":{"iopub.status.busy":"2024-07-10T02:52:28.264626Z","iopub.execute_input":"2024-07-10T02:52:28.264943Z","iopub.status.idle":"2024-07-10T02:52:28.276193Z","shell.execute_reply.started":"2024-07-10T02:52:28.264914Z","shell.execute_reply":"2024-07-10T02:52:28.275293Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"for epoch in range(num_epochs):\n    model.train()\n    total_loss = 0\n    for context, future_target in train_loader:\n        optimizer.zero_grad()\n#         print('x', context.shape)\n#         print('y', future_target.shape)\n\n        # Prepare inputs\n        past_values, past_time_features, past_observed_mask, future_values, future_time_features = \\\n            prepare_inputs(context, future_target, context_length, prediction_length, lags_sequence)\n\n#         print('past values shape', past_values.shape)\n#         print('future values shape', future_values.shape)\n#         print('past time features', past_time_features.shape)\n#         print('past mask', past_observed_mask.shape)\n#         print('future time features', future_time_features.shape)\n        \n        outputs = model(\n            past_values=past_values,\n            past_time_features=past_time_features,\n            past_observed_mask=past_observed_mask,\n           # static_categorical_features=None,\n          #  static_real_features=static_real_features,\n            future_values=future_values,\n            future_time_features=future_time_features\n        ).last_hidden_state\n        # Project the output to the desired dimension\n        projected_outputs = projection_layer(outputs[:, -config.prediction_length:, :])\n#         print('output shape', projected_outputs.shape)\n        loss = criterion(projected_outputs, future_values)\n#         loss = criterion(outputs[:, -prediction_length:, :], future_values)\n        loss.backward()\n        optimizer.step()\n        \n    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-10T02:52:28.277480Z","iopub.execute_input":"2024-07-10T02:52:28.277747Z","iopub.status.idle":"2024-07-10T02:52:56.667031Z","shell.execute_reply.started":"2024-07-10T02:52:28.277724Z","shell.execute_reply":"2024-07-10T02:52:56.665641Z"},"trusted":true},"execution_count":32,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[32], line 19\u001b[0m\n\u001b[1;32m     10\u001b[0m         past_values, past_time_features, past_observed_mask, future_values, future_time_features \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m     11\u001b[0m             prepare_inputs(context, future_target, context_length, prediction_length, lags_sequence)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#         print('past values shape', past_values.shape)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#         print('future values shape', future_values.shape)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#         print('past time features', past_time_features.shape)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#         print('past mask', past_observed_mask.shape)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#         print('future time features', future_time_features.shape)\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpast_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpast_time_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_time_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpast_observed_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_observed_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m           \u001b[49m\u001b[38;5;66;43;03m# static_categorical_features=None,\u001b[39;49;00m\n\u001b[1;32m     24\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;66;43;03m#  static_real_features=static_real_features,\u001b[39;49;00m\n\u001b[1;32m     25\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfuture_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfuture_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfuture_time_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfuture_time_features\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlast_hidden_state\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;66;03m# Project the output to the desired dimension\u001b[39;00m\n\u001b[1;32m     29\u001b[0m         projected_outputs \u001b[38;5;241m=\u001b[39m projection_layer(outputs[:, \u001b[38;5;241m-\u001b[39mconfig\u001b[38;5;241m.\u001b[39mprediction_length:, :])\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/autoformer/modeling_autoformer.py:1724\u001b[0m, in \u001b[0;36mAutoformerModel.forward\u001b[0;34m(self, past_values, past_time_features, past_observed_mask, static_categorical_features, static_real_features, future_values, future_time_features, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, output_hidden_states, output_attentions, use_cache, return_dict)\u001b[0m\n\u001b[1;32m   1709\u001b[0m     decoder_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(\n\u001b[1;32m   1710\u001b[0m         (\n\u001b[1;32m   1711\u001b[0m             torch\u001b[38;5;241m.\u001b[39mcat((seasonal_input[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlabel_length :, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m], zeros), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1714\u001b[0m         dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1715\u001b[0m     )\n\u001b[1;32m   1716\u001b[0m     trend_init \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(\n\u001b[1;32m   1717\u001b[0m         (\n\u001b[1;32m   1718\u001b[0m             torch\u001b[38;5;241m.\u001b[39mcat((trend_input[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlabel_length :, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m], mean), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1721\u001b[0m         dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1722\u001b[0m     )\n\u001b[0;32m-> 1724\u001b[0m     decoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1725\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrend_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1726\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1727\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1728\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1729\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1730\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1731\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1732\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1733\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1734\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1735\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1738\u001b[0m     decoder_outputs \u001b[38;5;241m=\u001b[39m AutoFormerDecoderOutput()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/autoformer/modeling_autoformer.py:1374\u001b[0m, in \u001b[0;36mAutoformerDecoder.forward\u001b[0;34m(self, trend, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1361\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1362\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m   1363\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1371\u001b[0m         use_cache,\n\u001b[1;32m   1372\u001b[0m     )\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1374\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1375\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1376\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1377\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1378\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1379\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1381\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m   1382\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1384\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1385\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1386\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1387\u001b[0m (hidden_states, residual_trend) \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1388\u001b[0m trend \u001b[38;5;241m=\u001b[39m trend \u001b[38;5;241m+\u001b[39m residual_trend\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/autoformer/modeling_autoformer.py:851\u001b[0m, in \u001b[0;36mAutoformerDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[38;5;66;03m# cross_attn cached key/values tuple is at positions 3,4 of present_key_value tuple\u001b[39;00m\n\u001b[1;32m    850\u001b[0m cross_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 851\u001b[0m hidden_states, cross_attn_weights, cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_value_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    859\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mdropout(hidden_states, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[1;32m    860\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/autoformer/modeling_autoformer.py:649\u001b[0m, in \u001b[0;36mAutoformerAttention.forward\u001b[0;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    645\u001b[0m         value_states_roll_delay \u001b[38;5;241m=\u001b[39m value_states\u001b[38;5;241m.\u001b[39mroll(shifts\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mint\u001b[39m(top_k_delays_index[i]), dims\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    647\u001b[0m     \u001b[38;5;66;03m# aggregation\u001b[39;00m\n\u001b[1;32m    648\u001b[0m     top_k_autocorrelations_at_delay \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 649\u001b[0m         \u001b[43mtop_k_autocorrelations\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, tgt_len, channel)\n\u001b[1;32m    650\u001b[0m     )\n\u001b[1;32m    651\u001b[0m     delays_agg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m value_states_roll_delay \u001b[38;5;241m*\u001b[39m top_k_autocorrelations_at_delay\n\u001b[1;32m    653\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m delays_agg\u001b[38;5;241m.\u001b[39mcontiguous()\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"# Evaluate the model\nmodel.eval()\nwith torch.no_grad():\n    test_loss = 0.0\n    for context, target in val_loader:\n        # Prepare inputs\n        past_values, past_time_features, past_observed_mask, future_values, future_time_features, static_real_features = \\\n        prepare_inputs(context, context_length, prediction_length, lags_sequence)\n        # Forward pass\n        outputs = model(past_values=past_values,\n                        past_time_features=past_time_features,\n                        past_observed_mask=past_observed_mask,\n                        static_categorical_features=None,  # No static categorical features\n                        static_real_features=static_real_features,\n                        future_values=future_values,\n                        future_time_features=future_time_features).last_hidden_state\n        \n        loss = criterion(outputs[:, -prediction_length], target)  # Compare only the last time step\n        test_loss += loss.item()\n    test_loss /= len(val_loader)\n    print(f\"Test Loss: {test_loss}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-10T02:52:56.668008Z","iopub.status.idle":"2024-07-10T02:52:56.668364Z","shell.execute_reply.started":"2024-07-10T02:52:56.668175Z","shell.execute_reply":"2024-07-10T02:52:56.668188Z"},"trusted":true},"execution_count":null,"outputs":[]}]}